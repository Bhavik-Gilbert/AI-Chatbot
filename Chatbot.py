# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HyE9nqFvgzrnY2CbvmEFW9mOTUgFia-q
"""



try:
  !pip install --upgrade google-cloud-vision==2.4.1 
  !pip install --upgrade google-cloud-language
except:
  pass

import numpy as np
import tensorflow.keras
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout
from keras.datasets import mnist
from PIL import Image, ImageOps
import io
from google.cloud import vision
from google.cloud import language
#from google.cloud.language import types, enums

def read_dictionary(file_path):
    responses = {}
    try:
        response_file = open(file_path, "r")
        lines = response_file.readlines()
        response_file.close()
        for line in lines:
            key, value = line.split(":")
            responses[key] = value
        return responses
    except:
        print("Error: Make sure your file is called", file_path)


def create_dictionary():
    file_path = input("Enter a file path (and extension) to save responses to: ")
    response_file = open(file_path, "w")
    while True:
        question = input("Enter a question: ")
        response = input("Enter a response: ")
        response_file.write("{}:{}\n".format(question, response))
        result = input("Would you like to continue (Y/N): ").lower()
        if result != "y":
            break
    response_file.close()


class Agent:
    def can_handle(self,  text):
        pass

    def get_response(self, text):
        pass

class ChatBot:
    def __init__(self):
        self.agents = []

    def add_agent(self, agent):
        self.agents.append(agent)

    def get_response(self, text):
        for agent in self.agents:
            if agent.can_handle(text):
                return agent.get_response(text)

        return "I'm sorry I don't understand " + text


class ConditionalAgent(Agent):
    def __init__(self, file_path):
        self.conditional_responses = read_dictionary(file_path)
    
    def can_handle(self, text):
        try:
          result = self.conditional_responses[text.lower()]
          return True
        except:
          return False
    
    def get_response(self, text):
        return self.conditional_responses[text.lower()]


class DigitRecognitionAgent(Agent):
    def __init__(self, file_path, image_folder):
        self.conditional_responses = read_dictionary(file_path)
        self.image_path = image_folder

        (x_train, y_train), (x_test, y_test) = mnist.load_data()
        x_train = x_train.reshape(60000, 784)
        x_test = x_test.reshape(10000, 784)
        x_train = x_train.astype("float32")
        x_test = x_test.astype("float32")

        x_train /= 255
        x_test /= 255

        y_train = to_categorical(y_train)
        y_test = to_categorical(y_test)

        self.model = Sequential()
        self.model.add(Dense(64, input_shape=(784,)))
        self.model.add(Activation('relu'))
        self.model.add(Dropout(0.2))
        self.model.add(Dense(10))
        self.model.add(Activation('softmax'))
        self.model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
        self.model.fit(x_train, y_train, epochs=4)
        score = self.model.evaluate(x_test, y_test)

    def can_handle(self, text):
        try:
          result = self.conditional_responses[text]
          return True
        except:
          return False


    def get_response(self, text):
          try:
            file_path = input("File Path: ")
            file_path = self.image_path + file_path
            test_image = np.invert(Image.open(file_path).convert("L"))
            test_image = test_image.reshape(1, 784)
            test_image = test_image.astype("float32")
            test_image /= 255
            pred = self.model.predict(test_image)
            return pred.argmax()
          except:
              return "Invalid file size"

class LandmarkDetectionAgent(Agent):
    def __init__(self, file_path, image_folder):
        self.conditional_responses = read_dictionary(file_path)
        self.image_path = image_folder
        self.client = vision.ImageAnnotatorClient.from_service_account_json("creds.json")
    
    def can_handle(self, text):
        try:
          result = self.conditional_responses[text]
          return True
        except:
          return False
    
    def get_response(self, text):
            file_path = input("File Path: ")
            file_path = self.image_path + file_path
            try:
              with io.open(file_path, "rb") as image_file:
                content = image_file.read()

              image = vision.Image(content=content)
              response = self.client.landmark_detection(image=image)
              landmarks = response.landmark_annotations
              if len(landmarks) == 0:
                print("No landmarks found")
              else:
                for landmark in landmarks:
                  print(landmark.description)
              return "All finished with landmarks"
            except:
              return "Invalid file"

class SentimentAnalysisAgent(Agent):
    def __init__(self, file_path):
        self.conditional_responses = read_dictionary(file_path)
        self.client = language.LanguageServiceClient.from_service_account_json("creds.json")
    
    def can_handle(self, text):
        try:
          result = self.conditional_responses[text]
          return True
        except:
          return False
    
    def get_response(self, text):
            user_input = input("Sentence: ")
            document = types.Document(content=user_input, type=enums.Document.Type.PLAIN_TEXT)
            response = self.client.analyze_sentiment(document=document, encoding_type="UTF32")
            sentences = response.sentences
            for sentence in sentences:
              print(sentence.text.content)
              print(sentence.sentiment.score)
            return ""


class CatOrDogAgent(Agent):
    def __init__(self, file_path, model_path, image_folder):
        self.conditional_responses = read_dictionary(file_path)
        self.image_path = image_folder
        np.set_printoptions(suppress=True)
        self.model = tensorflow.keras.models.load_model(model_path)
    
    def can_handle(self, text):
        try:
          result = self.conditional_responses[text]
          return True
        except:
          return False
    
    def get_response(self, text):
            file_path = input("File Path: ")
            file_path = self.image_path + file_path
            data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
            image = Image.open(file_path)
            size = (224, 224)
            image = ImageOps.fit(image, size, Image.ANTIALIAS)
            image_array = np.asarray(image)
            normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1
            data[0] = normalized_image_array
            pred = self.model.predict(data)
            if(pred.argmax()==1):
              return "I think it's a dog"
            elif(pred.argmax()==0):
              return "I think it's a cat"
            else:
              return "I'm not too sure what it is"

class EntityAnalysisAgent(Agent):
    def __init__(self, file_path):
        self.conditional_responses = read_dictionary(file_path)
        self.client = language.LanguageServiceClient.from_service_account_json("creds.json")
    
    def can_handle(self, text):
        try:
          result = self.conditional_responses[text]
          return True
        except:
          return False
    
    def get_response(self, text):
            user_input = input("Sentence: ")
            document = types.Document(content=user_input, type=enums.Document.Type.PLAIN_TEXT)
            response = client.analyze_entities(document=document, encoding_type="UTF32")
            entities = response.entities
            for entity in entities:
              print(entity.name)
              print(enums.Entity.Type(entity.type).name)
              print(entity)
            return ""

chatbot = ChatBot()

response_folder = "Responses/"
image_folder = "Images/"

simple_agent = ConditionalAgent(response_folder + "ConditionalAgent.txt")
digit_agent = DigitRecognitionAgent(response_folder + "DigitAgent.txt", image_folder)
landmark_agent = LandmarkDetectionAgent(response_folder + "LandmarkAgent.txt", image_folder)
sentiment_agent = SentimentAnalysisAgent(response_folder + "SentimentAgent.txt")
cat_or_dog_agent = CatOrDogAgent(response_folder + "CatOrDogAgent.txt", "keras_model.h5", image_folder)
entity_agent = EntityAnalysisAgent(response_folder + "EntityAgent.txt")

chatbot.add_agent(simple_agent)
chatbot.add_agent(digit_agent)
chatbot.add_agent(landmark_agent)
chatbot.add_agent(sentiment_agent)
chatbot.add_agent(cat_or_dog_agent)
chatbot.add_agent(entity_agent)

bots = [["Digit Recognition Agent" , response_folder + "DigitAgent.txt"], ["Landmark Detection Agent", response_folder + "LandmarkAgent.txt"], 
        ["Sentiment Analysis Agent", response_folder + "SentimentAgent.txt"], ["Cat Or Dog Agent", response_folder + "CatOrDogAgent.txt"],
        ["Entity Analysis Agent", response_folder + "EntityAgent.txt"]]

while True:
    print("Hi, what would you like me to do?")
    user_input = input("")
    if user_input.lower() == "goodbye" or user_input.lower() == "quit":
        break
    if user_input.lower() == "commands":
      for agents in bots:
        print(agents[0] + "'s trigger words =>")
        commands = read_dictionary(agents[1])
        for command in commands:
          print(command)
        print("")
      continue

    response = chatbot.get_response(user_input)
    print(response)
    print("")